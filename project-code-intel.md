---
layout: page
title: Safe and Explainable AI for Code 
---

<div style="font-family: 'Alata'; font-size: small;">
<span>Aftab Hussain<sup>1</sup>, Md Rafiqul Islam Rabin<sup>1</sup>, Mohammad Amin
Alipour<sup>1</sup>, Vincent J. Hellendoorn<sup>2</sup>, Bowen Xu<sup>3</sup>,
Omprakash Gnawali<sup>1</sup>, Sen Lin<sup>1</sup>, Toufique Ahmed<sup>4</sup>,
Premkumar Devanbu<sup>4</sup>, Navid Ayoobi<sup>1</sup>, David Lo<sup>5</sup>,
Sahil Suneja<sup>6</sup> <br></span>
<span style="color: gray; font-size: small;">University of Houston<sup>1</sup>,
Carnegie Mellon University<sup>2</sup>, North Carolina State
University<sup>3</sup>, University of California, Davis<sup>4</sup>, Singapore
Management University<sup>5</sup>, IBM Research<sup>6</sup>
<br> Supported by <a href = "https://www.sri.com/">SRI International</a>, <a
href = "https://www.iarpa.gov/">IARPA</a>
<br> 2021 to present</span> 
<br><span class="material-symbols-outlined" style="color: #1ba2d6;">arrow_back</span><b><a href="../Projects/index.html#code-intel-menu">Return to Projects</a></b>
<br>
<br>
</div>

<style>
img {
  display: block;
  margin-left: auto;
  margin-right: auto;
  max-width: 100%;
  height: auto;
}
</style>

<img src="../images/projects/code-intel/ai-background.jpg" alt="drawing"/>


This extensive project comprises of several sub-projects delving into two
aspects: (1) the behavior (Explainable AI for Code) and (2) the security
vulnerabilities (Safe AI for Code) of massive deep neural models in the coding
domain. (A dedicated page for the Safe AI for Code segment may be found
[here](http://babylon.cs.uh.edu/web/)). The models we investigate range in size from millions to billions of
parameters; they include transformer-based Large Language Models (LLMs) like
Microsoft's **CodeBERT**, Salesforce's **CodeT5**, Meta's **PLBART**,
**Llama2**, and **CodeLlama**, BigCode's **StarCoder**, against attacks on
software development tasks including **defect detection**, **clone detection**,
and **text-to-code generation**.  Our works include model probing and black box
techniques that involve fine-tuning the models on noisy and poisoned code
datasets derived from benchmark sources like Microsoft's **CodeXGLUE**,
utilizing NVIDIA A100 GPUs. Here is a list of the works in this project: 

## [Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code](../project-params-embeds/index.html) 
<div style="font-family: 'Alata';">
    <span style="color: gray; font-size: small;">AIware'24: 1st ACM
International Conference on AI-powered Software, co-located with the ACM
International Conference on the Foundations of Software Engineering (FSE),
2024, Porto de Galinhas, Brazil <br></span>
    <span class="material-symbols-outlined" style="color: #1ba2d6;">label</span>
    <span style="color: #1ba2d6; font-size: small;">Safe AI for Code</span>
</div>

_____________


## [On Trojan Signatures in Large Language Models of Code](../project-trojan-sig/index.html) 
<div style="font-family: 'Alata';">
    <span style="color: gray; font-size: small;"> International Conference on
Learning Representations Workshop on Secure and Trustworthy Large Language
Models (SeT LLM at ICLR '24), 2024, Vienna, Austria <br></span>
    <span class="material-symbols-outlined" style="color: #1ba2d6;">label</span>
    <span style="color: #1ba2d6; font-size: small;">Safe AI for Code</span>
</div>

_____________


## [A Study of Variable-Role-based Feature Enrichment in Neural Models of Code](../project-roles/index.html) 
<div style="font-family: 'Alata';">
    <span style="color: gray; font-size: small;">InteNSE'23: The 1st International Workshop on Interpretability and
Robustness in Neural Software Engineering, co-located with the 45th
International Conference on Software Engineering, ICSE 2023, Melbourne,
Australia  <br></span>
    <span class="material-symbols-outlined" style="color: #1ba2d6;">label</span>
    <span style="color: #1ba2d6; font-size: small;">Explainable AI for Code</span>
</div>

_____________


## [Memorization and Generalization in Neural Code Intelligence Models](../project-mem-gen/index.html) 
<div style="font-family: 'Alata';">
    <span style="color: gray; font-size: small;">Journal of Information and Software Technology, 2023
<br></span>
    <span class="material-symbols-outlined" style="color: #1ba2d6;">label</span>
    <span style="color: #1ba2d6; font-size: small;">Explainable AI for Code</span>
</div>

_____________

<p style="color:gray;font-size:8pt;"><small>Image:<a href="https://www.freepik.com/free-photo/virtual-projection-lights-forming-square-pattern-dark-background_13500430.htm#fromView=search&page=4&position=52&uuid=2464b102-c894-41db-ba6c-24ff2d6ce136" target="_blank">Freepik</a></small></p>
