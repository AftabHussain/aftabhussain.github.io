
<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">

	   <p>Earlier this fall, I was invited to a Global Cyber‚ÄëCEOs Roundtable at the
     <a href="https://na.eventscloud.com/website/87265/summit-program/" target="_blank" rel="noopener noreferrer">
       Global Cyber Research Institute Summit‚ÄØ2025.
     </a>In the main event, I also presented my poster: <em>‚ÄúFinding Trojan Triggers in Code‚ÄØLLMs: An Occlusion‚Äëbased Human‚Äëin‚Äëthe‚Äëloop Approach.‚Äù</em></p>

  <p>The panel featured 
     <a href="https://www.linkedin.com/in/symeonid/" target="_blank" rel="noopener noreferrer"><strong>Andreas‚ÄØSymeonidis</strong></a>,
     <a href="https://www.linkedin.com/in/coleknuth/" target="_blank" rel="noopener noreferrer"><strong>Cole‚ÄØKnuth</strong></a>,
     <a href="https://www.linkedin.com/in/chad-spensky/" target="_blank" rel="noopener noreferrer"><strong>Chad‚ÄØSpensky</strong></a>, and
     <a href="https://www.linkedin.com/in/jassoncasey/" target="_blank" rel="noopener noreferrer"><strong>Jasson‚ÄØCasey</strong></a></p>, who led an amazing discussion, and gave wonderful talks in the Summit. 

  <p>Insightful Takeaways:</p>

  <p>üîë Identity is multi-dimensional ‚Äî we need to verify who, what device, and what authority acts.</p>
  <p>üîë AI accelerates work but increases risks, e.g., data exposure.</p>
  <p>üîë Operational technology sectors are digitizing cautiously ‚Äî human-in-the-loop verification is essential.</p>
  <p>üîë Quick AI-based fixes may grab attention, but secure architecture and testing is still important.</p>
  <p>üîë Bridging research and practice drives real-world resilience.</p>

 <br><span style="color:gray;font-size:9pt">
Sun, 2 Nov 2025
</span>  </span>  </div>
 <br>




<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
My PhD thesis and defense slides on <strong>Trojan Detection in Large Language Models of Code</strong> are now available online.  
  If you're interested in LLM security or code LLM vulnerabilities, feel free to take a look:  
  <a href="https://uh-ir.tdl.org/server/api/core/bitstreams/960b6bf7-7f3c-4385-bb4c-30f95d5f01bb/content" target="_blank">Thesis</a> | 
  <a href="https://aftabhussain.github.io/documents/pubs/phd-research-presentation_defense.pdf" target="_blank">Slides</a>
<a href=  ""  target="_blank">
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 24 May 2025
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Recently invited to contribute as a Reviewer for the <strong>Springer 
Empirical Software Engineering Journal</strong>.
<a href=  "https://link.springer.com/journal/10664"  target="_blank">https://link.springer.com/journal/10664
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 24 May 2025
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Recently invited to contribute as a Reviewer for <strong>IEEE‚Äôs Transactions on Software Engineering (TSE) Journal</strong>.
<a href=  "https://www.computer.org/csdl/journal/ts"  target="_blank">https://www.computer.org/csdl/journal/ts
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 07 May 2025
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Participated as a panel member at the <strong>First Texas A&M Connected Intelligence Workshop</strong> in a discussion on ‚ÄúBeyond Generation: Is Reasoning the Next Leap in AI?‚Äù exploring the future of reasoning in AI, its relationship to human cognition, and implications for data, model design, and real-world applications.
<a href=  "https://www.linkedin.com/posts/activity-7310999260148219904--Iyz?utm_source=share&utm_medium=member_desktop&rcm=ACoAAA1MWGoBhfyKc3dqZ-DK8Tkz-dhRzmylDQ8"  target="_blank">
https://www.linkedin.com/posts/activity-7310999260148219904--Iyz?utm_source=share&utm_medium=member_desktop&rcm=ACoAAA1MWGoBhfyKc3dqZ-DK8Tkz-dhRzmylDQ8
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 08 April 2025
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Recently invited to contribute as a Reviewer for the <strong>IEEE Transactions on Dependable and Secure Computing (TDSC) Journal</strong>.
<a href=  "https://www.computer.org/csdl/journal/tq"  target="_blank">
https://www.computer.org/csdl/journal/tq
</a>  <br><span style="color:gray;font-size:9pt">
Thu, 06 March 2025
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Recently invited to contribute as a Reviewer for the <strong>ACM Transactions on Software Engineering and Methodology (TOSEM) Journal</strong>.
<a href=  "https://dl.acm.org/journal/tosem"  target="_blank">
https://dl.acm.org/journal/tosem
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 22 January 2025
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
	 Check out the slides of two of our recent works on Safety of Code LLMs, which I recently presented at <a href="https://2024.aiwareconf.org/" target="_blank">AIWare 2024, Porto de Galinhas:</a>
<a href="https://aftabhussain.github.io/documents/pubs/aiware2024_critical-review_slides.pdf"  target="_blank">
Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy
</a>and<a href="https://aftabhussain.github.io/documents/pubs/aiware2024_poisoning-impacts_slides.pdf"  target="_blank">
Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code
</a> 

<br><span style="color:gray;font-size:9pt">
Sun, 28 July 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Participated in a panel at the <strong>1st ACM International Conference on AI-Powered Software Security and Safety</strong>, discussing trojans in large language models of code (Code-LLMs).
<a href=  ""  target="_blank">

</a>  <br><span style="color:gray;font-size:9pt">
Mon, 15 July 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Here's a link to our poster presented at last month's <strong>SeT LLM at ICLR ‚Äô24 (The International Conference on Learning Representations Workshop on Secure and Trustworthy Large Language Models</strong>, at Vienna, Austria:
<a href=  "https://aftabhussain.github.io/documents/pubs/setllm24-trojan-signatures-poster.pdf"  target="_blank">
https://aftabhussain.github.io/documents/pubs/setllm24-trojan-signatures-poster.pdf
</a>  <br><span style="color:gray;font-size:9pt">
Sat, 08 June 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our paper, "Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy", has been accepted in next month's AIware'24, the 1st ACM International Conference on AI-powered Software, Late Breaking arXiv Track, co-located with the ACM International Conference on the Foundations of Software Engineering (FSE), at Porto de Galinhas, Brazil. Learn more about this work here:
<a href=  "https://arxiv.org/abs/2405.02828"  target="_blank">
https://arxiv.org/abs/2405.02828
</a>  <br><span style="color:gray;font-size:9pt">
Fri, 07 June 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our paper, "Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code", has been accepted in next month's AIware'24, the 1st ACM International Conference on AI-powered Software, co-located with the ACM International Conference on the Foundations of Software Engineering (FSE), at Porto de Galinhas, Brazil. Learn more about this work here:
<a href=  "https://aftabhussain.github.io/project-params-embeds/index.html"  target="_blank">
https://aftabhussain.github.io/project-params-embeds/index.html
</a>  <br><span style="color:gray;font-size:9pt">
Fri, 07 June 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
A dedicated page for the Safe and Explainable AI for Code project has been added, showcasing several of our works. Stay tuned for more works.
<a href=  "https://aftabhussain.github.io/project-code-intel/index.html"  target="_blank">
https://aftabhussain.github.io/project-code-intel/index.html
</a>  <br><span style="color:gray;font-size:9pt">
Thu, 06 June 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Looking forward to presenting our work on trojan signature detection at SeT LLM (Secure and Trustworthy LLMs) Workshop at ICLR 2024, let's connect if you are also attending. Know more about the work in my post here:
<a href=  "https://www.linkedin.com/posts/activity-7192681939336597504-A1kN?utm_source=share&utm_medium=member_desktop"  target="_blank">
https://www.linkedin.com/posts/activity-7192681939336597504-A1kN?utm_source=share&utm_medium=member_desktop
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 05 May 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our work on trojan detection in Code LLMs has received the Runners-up recognition for the People‚Äôs Choice Award, Runners-up recognition for the Judge‚Äôs Award at the UH CS PhD Research Showcase 2024, last month. We hope the work would foster more research in the area.
<a href=  "https://aftabhussain.github.io/documents/pubs/uh-phd-showcase-trojan-detection-poster.pdf"  target="_blank">
https://aftabhussain.github.io/documents/pubs/uh-phd-showcase-trojan-detection-poster.pdf
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 30 April 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
The exploration of Trojans in Code Large Language Models (LLMs) is gaining significant importance, driven by the increasing adoption of Code LLMs among developers. 

My recent PhD proposal on our contributions in the area has been approved by my PhD Committee. I express my gratitude to Prof. Amin Alipour (University of Houston), Prof. Omprakash Gnawali (University of Houston), Prof. Sen Lin (University of Houston), Vincent Hellendoorn (Carnegie Mellon University/Google), Bowen Xu (North Carolina State University), for giving the green light for further exploring interesting directions in the area. We hope our contributions would benefit the broader scientific community and beyond.
<a href=  "https://www.linkedin.com/posts/activity-7184597356267335680-byqY?utm_source=share&utm_medium=member_desktop"  target="_blank">
https://www.linkedin.com/posts/activity-7184597356267335680-byqY?utm_source=share&utm_medium=member_desktop
</a>  <br><span style="color:gray;font-size:9pt">
Fri, 12 April 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Here are some nice posters we found on neural model backdoors and other interesting topics from our NeurIPS Trip to New Orleans, last year December, check them out and comment:
<a href=  "https://drive.google.com/drive/folders/1d_QEJ_9sbYbij1vtFqMXC0k7bkGEtSNl?usp=sharing"  target="_blank">
https://drive.google.com/drive/folders/1d_QEJ_9sbYbij1vtFqMXC0k7bkGEtSNl?usp=sharing
</a>  <br><span style="color:gray;font-size:9pt">
Sat, 02 March 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Large language models (LLMs) are now a key part of software development. They learn from huge code datasets, but verifying each data point is tough. There's a risk of injecting malicious data (trojans) during training, making models vulnerable. This sneaky move can compromise model integrity and mess with downstream tasks that are deployed by the models. Meet OSeql, our new defense techique for spotting trojan-triggering inputs in code. Our results? Almost 100% recall in detecting trojaned inputs and over 90% accuracy in identifying triggers. We put OSeql to the test on trojaned versions of CodeBERT, PLBART, CodeT5, BART, and RoBERTa. Thanks a lot M.R.I. Rabin, Toufique Ahmed, Amin Alipour, Bowen Xu for all your efforts towards this collaboration.
<a href=  "https://arxiv.org/abs/2312.04004"  target="_blank">
https://arxiv.org/abs/2312.04004
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 10 December 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
[Related to last post] Here's our talk on "A Study of Variable-Role-based Feature Enrichment in Neural Models of Code"
<a href=  "https://www.youtube.com/watch?v=hgdzHiBMo6Y"  target="_blank">
https://www.youtube.com/watch?v=hgdzHiBMo6Y
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 05 November 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Knowing variable roles in code has been found to be helpful by students in learning programming -- could variable roles help deep neural models in performing coding tasks? We do an exploratory study in this work presented at the 2023 INTENSE workshop (co-located with ICSE 2023). Publication:
<a href=  "https://www.computer.org/csdl/proceedings-article/intense/2023/017200a014/1P4kEfsqveg"  target="_blank">
https://www.computer.org/csdl/proceedings-article/intense/2023/017200a014/1P4kEfsqveg
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 05 November 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our short critique of "Stealthy Backdoor Attack for Code Models" (Yang et al., 2023) on Medium:
<a href=  "https://medium.com/@aftab.hussain46/reflections-on-afraidoor-a-stealthy-trigger-generation-approach-for-backdoor-attacks-on-neural-acf9f6c329fb"  target="_blank">
https://medium.com/@aftab.hussain46/reflections-on-afraidoor-a-stealthy-trigger-generation-approach-for-backdoor-attacks-on-neural-acf9f6c329fb
</a>  <br><span style="color:gray;font-size:9pt">
Fri, 24 March 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Can programming concepts used to teach students help deep neural models of code? Check out the preprint of our investigation that has been accepted in The 1st IEEE/ACM International Workshop on Interpretability and Robustness in Neural Software Engineering (InteNSE'23), Melbourne, Australia, 2023 (Co-located with ICSE).
<a href=  "https://arxiv.org/abs/2303.04942"  target="_blank">
https://arxiv.org/abs/2303.04942
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 22 March 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
What features cast doubt about a prediction, or potentially hinder a model‚Äôs confidence? Check out the preprint of our investigation that has been accepted in The 1st IEEE/ACM International Workshop on Interpretability and Robustness in Neural Software Engineering (InteNSE'23), Melbourne, Australia, 2023 (Co-located with ICSE)
<a href=  "https://arxiv.org/abs/2303.01739"  target="_blank">
https://arxiv.org/abs/2303.01739
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 22 March 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Are deep learning models memorizing your data instead of learning patterns? Recent works suggest memorization risk is high with noisy training data. In our latest exploration, we see the extent of memorization in neural code intelligence models (models that can automatically do certain coding tasks), and provide insights on how memorization may impact the learning behaviour of such models. Check out our article for free before November 09, 2022.
<a href=  "https://authors.elsevier.com/a/1fnUS3O8rCcj5S"  target="_blank">
https://authors.elsevier.com/a/1fnUS3O8rCcj5S
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 12 October 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Check out Readle, A Formal Framework for Designing AI-based Edge Systems based on RTL and BDDs.
<a href=  "https://arxiv.org/abs/2205.09239"  target="_blank">
https://arxiv.org/abs/2205.09239
</a>  <br><span style="color:gray;font-size:9pt">
Sat, 21 May 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
See my talk on Removing Uninteresting Bytes in Software Fuzzing at the 5th International Workshop on the Next Level of Test Automation (NEXTA 2022)
<a href=  "https://www.youtube.com/watch?v=iRU8Rfd6Fcc"  target="_blank">
https://www.youtube.com/watch?v=iRU8Rfd6Fcc
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 13 April 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our investigation into the effect of reducing seeds on fuzzing has been accepted in the 5th International Workshop on the Next Level of Test Automation (NEXTA '22). Preprint:
<a href=  "https://arxiv.org/abs/2112.13297"  target="_blank">
https://arxiv.org/abs/2112.13297
</a>  <br><span style="color:gray;font-size:9pt">
Thu, 17 February 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
IBM Neuro-Symbolic AI Workshop 2022
<a href=  "https://www.eventbrite.com/x/ibm-neuro-symbolic-ai-workshop-2022-tickets-228395145027"  target="_blank">
https://www.eventbrite.com/x/ibm-neuro-symbolic-ai-workshop-2022-tickets-228395145027
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 19 January 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Check out our work on Testing the Robustness of a BiLSTM-based Structural Story Classifier
<a href=  "https://arxiv.org/abs/2201.02733"  target="_blank">
https://arxiv.org/abs/2201.02733
</a>  <br><span style="color:gray;font-size:9pt">
Mon, 3 January 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Can reduced seeds lead to more effective fuzzing? We build a new coverage-based reducer called DIAR to explore this.
<a href=  "https://arxiv.org/abs/2112.13297?context=cs"  target="_blank">
https://arxiv.org/abs/2112.13297?context=cs
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 28 December 2021
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Check out our new tool called FMViz that visualizes tests generated by AFL
<a href=  "https://github.com/AftabHussain/afl-test-viz"  target="_blank">
https://github.com/AftabHussain/afl-test-viz
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 28 December 2021
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Intel Innovation Event October 27-28 2021
<a href=  "https://www.intel.com/content/www/us/en/events/on-event-series.html"  target="_blank">
https://www.intel.com/content/www/us/en/events/on-event-series.html
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 20 October 2021
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
Strategic Considerations When Outsourcing Your Software Development, CrunchBase
<a 
href=
"https://news.crunchbase.com/news/strategic-considerations-when-outsourcing-your-software-development/"
target="_blank">
https://news.crunchbase.com/news/strategic-considerations-when-outsourcing-your-software-development/
</a>
<br><span style="color:gray;font-size:9pt">
Fri, 15 October 2021
</span>
</span>
</div>

<br>


<div class="verticalLine">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
Microsoft Research Summit: 
<a 
href=
"https://researchsummit.microsoft.com/home_public/?OCID=msr_researchsummit_webpage_LI_AD1_Generic" 
target="_blank">
https://researchsummit.microsoft.com/home_public/?OCID=msr_researchsummit_webpage_LI_AD1_Generic 
</a>
<br><span style="color:gray;font-size:9pt">
Wed, 13 October 2021
</span>
</span>
</div>

<br>

<div class="verticalLine">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
CISQ 9th Annual Cyber Resilience Summit:
<a 
href=
"https://www.it-cisq.org/cyber-resilience-summit-2021/index.htm"
target="_blank">https://www.it-cisq.org/cyber-resilience-summit-2021/index.htm
</a>
<br>- Publicly Available Standards: <a href="https://standards.iso.org/ittf/PubliclyAvailableStandards/index.html">https://standards.iso.org/ittf/PubliclyAvailableStandards/index.html</a>
<br><span style="color:gray;font-size:9pt">
Tue, 12 October 2021
<br>
</span>
</span>
</div>

<br>

<div class="verticalLine">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
Google Systems Innovation Summit 2021: 
<a 
href=
"https://events.withgoogle.com/google-systems-innovation-summit-2021/#content"
target="_blank">
https://events.withgoogle.com/google-systems-innovation-summit-2021/#content
</a>
<br><span style="color:gray;font-size:9pt">
Fri, 8 October 2021
</span>
</span>
</div>
