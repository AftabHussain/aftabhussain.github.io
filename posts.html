<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
A dedicated page for the Safe and Explainable AI for Code project has been added, showcasing several of our works. Stay tuned for more works.
<a href=  "https://aftabhussain.github.io/project-code-intel/index.html"  target="_blank">
https://aftabhussain.github.io/project-code-intel/index.html
</a>  <br><span style="color:gray;font-size:9pt">
Thu, 06 June 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Looking forward to presenting our work on trojan signature detection at SeT LLM (Secure and Trustworthy LLMs) Workshop at ICLR 2024, let's connect if you are also attending. Know more about the work in my post here:
<a href=  "https://www.linkedin.com/posts/activity-7192681939336597504-A1kN?utm_source=share&utm_medium=member_desktop"  target="_blank">
https://www.linkedin.com/posts/activity-7192681939336597504-A1kN?utm_source=share&utm_medium=member_desktop
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 05 May 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our work on trojan detection in Code LLMs has received the Runners-up recognition for the People’s Choice Award, Runners-up recognition for the Judge’s Award at the UH CS PhD Research Showcase 2024, last month. We hope the work would foster more research in the area.
<a href=  "https://aftabhussain.github.io/documents/pubs/uh-phd-showcase-trojan-detection-poster.pdf"  target="_blank">
https://aftabhussain.github.io/documents/pubs/uh-phd-showcase-trojan-detection-poster.pdf
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 30 April 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
The exploration of Trojans in Code Large Language Models (LLMs) is gaining significant importance, driven by the increasing adoption of Code LLMs among developers. 

My recent PhD proposal on our contributions in the area has been approved by my PhD Committee. I express my gratitude to Prof. Amin Alipour (University of Houston), Prof. Omprakash Gnawali (University of Houston), Prof. Sen Lin (University of Houston), Vincent Hellendoorn (Carnegie Mellon University/Google), Bowen Xu (North Carolina State University), for giving the green light for further exploring interesting directions in the area. We hope our contributions would benefit the broader scientific community and beyond.
<a href=  "https://www.linkedin.com/posts/activity-7184597356267335680-byqY?utm_source=share&utm_medium=member_desktop"  target="_blank">
https://www.linkedin.com/posts/activity-7184597356267335680-byqY?utm_source=share&utm_medium=member_desktop
</a>  <br><span style="color:gray;font-size:9pt">
Fri, 12 April 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Here are some nice posters we found on neural model backdoors and other interesting topics from our NeurIPS Trip to New Orleans, last year December, check them out and comment:
<a href=  "https://drive.google.com/drive/folders/1d_QEJ_9sbYbij1vtFqMXC0k7bkGEtSNl?usp=sharing"  target="_blank">
https://drive.google.com/drive/folders/1d_QEJ_9sbYbij1vtFqMXC0k7bkGEtSNl?usp=sharing
</a>  <br><span style="color:gray;font-size:9pt">
Sat, 02 March 2024
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Large language models (LLMs) are now a key part of software development. They learn from huge code datasets, but verifying each data point is tough. There's a risk of injecting malicious data (trojans) during training, making models vulnerable. This sneaky move can compromise model integrity and mess with downstream tasks that are deployed by the models. Meet OSeql, our new defense techique for spotting trojan-triggering inputs in code. Our results? Almost 100% recall in detecting trojaned inputs and over 90% accuracy in identifying triggers. We put OSeql to the test on trojaned versions of CodeBERT, PLBART, CodeT5, BART, and RoBERTa. Thanks a lot M.R.I. Rabin, Toufique Ahmed, Amin Alipour, Bowen Xu for all your efforts towards this collaboration.
<a href=  "https://arxiv.org/abs/2312.04004"  target="_blank">
https://arxiv.org/abs/2312.04004
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 10 December 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
[Related to last post] Here's our talk on "A Study of Variable-Role-based Feature Enrichment in Neural Models of Code"
<a href=  "https://www.youtube.com/watch?v=hgdzHiBMo6Y"  target="_blank">
https://www.youtube.com/watch?v=hgdzHiBMo6Y
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 05 November 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Knowing variable roles in code has been found to be helpful by students in learning programming -- could variable roles help deep neural models in performing coding tasks? We do an exploratory study in this work presented at the 2023 INTENSE workshop (co-located with ICSE 2023). Publication:
<a href=  "https://www.computer.org/csdl/proceedings-article/intense/2023/017200a014/1P4kEfsqveg"  target="_blank">
https://www.computer.org/csdl/proceedings-article/intense/2023/017200a014/1P4kEfsqveg
</a>  <br><span style="color:gray;font-size:9pt">
Sun, 05 November 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our short critique of "Stealthy Backdoor Attack for Code Models" (Yang et al., 2023) on Medium:
<a href=  "https://medium.com/@aftab.hussain46/reflections-on-afraidoor-a-stealthy-trigger-generation-approach-for-backdoor-attacks-on-neural-acf9f6c329fb"  target="_blank">
https://medium.com/@aftab.hussain46/reflections-on-afraidoor-a-stealthy-trigger-generation-approach-for-backdoor-attacks-on-neural-acf9f6c329fb
</a>  <br><span style="color:gray;font-size:9pt">
Fri, 24 March 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Can programming concepts used to teach students help deep neural models of code? Check out the preprint of our investigation that has been accepted in The 1st IEEE/ACM International Workshop on Interpretability and Robustness in Neural Software Engineering (InteNSE'23), Melbourne, Australia, 2023 (Co-located with ICSE).
<a href=  "https://arxiv.org/abs/2303.04942"  target="_blank">
https://arxiv.org/abs/2303.04942
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 22 March 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
What features cast doubt about a prediction, or potentially hinder a model’s confidence? Check out the preprint of our investigation that has been accepted in The 1st IEEE/ACM International Workshop on Interpretability and Robustness in Neural Software Engineering (InteNSE'23), Melbourne, Australia, 2023 (Co-located with ICSE)
<a href=  "https://arxiv.org/abs/2303.01739"  target="_blank">
https://arxiv.org/abs/2303.01739
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 22 March 2023
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Are deep learning models memorizing your data instead of learning patterns? Recent works suggest memorization risk is high with noisy training data. In our latest exploration, we see the extent of memorization in neural code intelligence models (models that can automatically do certain coding tasks), and provide insights on how memorization may impact the learning behaviour of such models. Check out our article for free before November 09, 2022.
<a href=  "https://authors.elsevier.com/a/1fnUS3O8rCcj5S"  target="_blank">
https://authors.elsevier.com/a/1fnUS3O8rCcj5S
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 12 October 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Check out Readle, A Formal Framework for Designing AI-based Edge Systems based on RTL and BDDs.
<a href=  "https://arxiv.org/abs/2205.09239"  target="_blank">
https://arxiv.org/abs/2205.09239
</a>  <br><span style="color:gray;font-size:9pt">
Sat, 21 May 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
See my talk on Removing Uninteresting Bytes in Software Fuzzing at the 5th International Workshop on the Next Level of Test Automation (NEXTA 2022)
<a href=  "https://www.youtube.com/watch?v=iRU8Rfd6Fcc"  target="_blank">
https://www.youtube.com/watch?v=iRU8Rfd6Fcc
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 13 April 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Our investigation into the effect of reducing seeds on fuzzing has been accepted in the 5th International Workshop on the Next Level of Test Automation (NEXTA '22). Preprint:
<a href=  "https://arxiv.org/abs/2112.13297"  target="_blank">
https://arxiv.org/abs/2112.13297
</a>  <br><span style="color:gray;font-size:9pt">
Thu, 17 February 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
IBM Neuro-Symbolic AI Workshop 2022
<a href=  "https://www.eventbrite.com/x/ibm-neuro-symbolic-ai-workshop-2022-tickets-228395145027"  target="_blank">
https://www.eventbrite.com/x/ibm-neuro-symbolic-ai-workshop-2022-tickets-228395145027
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 19 January 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Check out our work on Testing the Robustness of a BiLSTM-based Structural Story Classifier
<a href=  "https://arxiv.org/abs/2201.02733"  target="_blank">
https://arxiv.org/abs/2201.02733
</a>  <br><span style="color:gray;font-size:9pt">
Mon, 3 January 2022
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Can reduced seeds lead to more effective fuzzing? We build a new coverage-based reducer called DIAR to explore this.
<a href=  "https://arxiv.org/abs/2112.13297?context=cs"  target="_blank">
https://arxiv.org/abs/2112.13297?context=cs
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 28 December 2021
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Check out our new tool called FMViz that visualizes tests generated by AFL
<a href=  "https://github.com/AftabHussain/afl-test-viz"  target="_blank">
https://github.com/AftabHussain/afl-test-viz
</a>  <br><span style="color:gray;font-size:9pt">
Tue, 28 December 2021
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
 <span style="font-size:10pt;display:inline-block;margin-left:10px">
Intel Innovation Event October 27-28 2021
<a href=  "https://www.intel.com/content/www/us/en/events/on-event-series.html"  target="_blank">
https://www.intel.com/content/www/us/en/events/on-event-series.html
</a>  <br><span style="color:gray;font-size:9pt">
Wed, 20 October 2021
</span>  </span>  </div> 
 <br>

<div class="verticalLine dont-break-out">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
Strategic Considerations When Outsourcing Your Software Development, CrunchBase
<a 
href=
"https://news.crunchbase.com/news/strategic-considerations-when-outsourcing-your-software-development/"
target="_blank">
https://news.crunchbase.com/news/strategic-considerations-when-outsourcing-your-software-development/
</a>
<br><span style="color:gray;font-size:9pt">
Fri, 15 October 2021
</span>
</span>
</div>

<br>


<div class="verticalLine">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
Microsoft Research Summit: 
<a 
href=
"https://researchsummit.microsoft.com/home_public/?OCID=msr_researchsummit_webpage_LI_AD1_Generic" 
target="_blank">
https://researchsummit.microsoft.com/home_public/?OCID=msr_researchsummit_webpage_LI_AD1_Generic 
</a>
<br><span style="color:gray;font-size:9pt">
Wed, 13 October 2021
</span>
</span>
</div>

<br>

<div class="verticalLine">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
CISQ 9th Annual Cyber Resilience Summit:
<a 
href=
"https://www.it-cisq.org/cyber-resilience-summit-2021/index.htm"
target="_blank">https://www.it-cisq.org/cyber-resilience-summit-2021/index.htm
</a>
<br>- Publicly Available Standards: <a href="https://standards.iso.org/ittf/PubliclyAvailableStandards/index.html">https://standards.iso.org/ittf/PubliclyAvailableStandards/index.html</a>
<br><span style="color:gray;font-size:9pt">
Tue, 12 October 2021
<br>
</span>
</span>
</div>

<br>

<div class="verticalLine">
<span style="font-size:10pt;display:inline-block;margin-left:10px">
Google Systems Innovation Summit 2021: 
<a 
href=
"https://events.withgoogle.com/google-systems-innovation-summit-2021/#content"
target="_blank">
https://events.withgoogle.com/google-systems-innovation-summit-2021/#content
</a>
<br><span style="color:gray;font-size:9pt">
Fri, 8 October 2021
</span>
</span>
</div>
